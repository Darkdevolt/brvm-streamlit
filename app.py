import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime

# Configuration de la page
st.set_page_config(page_title="Cours BRVM", page_icon="üìà", layout="wide")
st.title("üìä Cours des Actions BRVM")
st.caption("Scraping direct du site officiel de la BRVM")

# URL cible
url = "https://www.brvm.org/fr/cours-actions/0"

@st.cache_data(ttl=3600)  # Cache les donn√©es pendant 1 heure
def scrape_brvm_data():
    """Fonction pour scraper les donn√©es de la BRVM - Version scraping uniquement"""
    try:
        # Requ√™te HTTP avec headers
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'fr,fr-FR;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # Debug: afficher l'URL
        st.sidebar.write(f"Tentative de connexion √†: {url}")
        
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()  # L√®ve une exception pour les codes 4xx/5xx
        
        # V√©rifier le contenu
        if len(response.content) < 1000:
            raise Exception("R√©ponse trop courte, site peut-√™tre bloqu√©")
        
        # Parser le contenu HTML
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Debug: afficher la taille du HTML
        st.sidebar.write(f"HTML re√ßu: {len(response.content)} caract√®res")
        
        # Trouver le tableau - approche robuste
        table = None
        
        # Essayer plusieurs m√©thodes pour trouver le tableau
        # 1. Chercher par les en-t√™tes
        tables = soup.find_all('table')
        for tbl in tables:
            th_texts = [th.get_text(strip=True) for th in tbl.find_all('th')]
            if any('Symbole' in text for text in th_texts):
                table = tbl
                break
        
        # 2. Si pas trouv√©, prendre la premi√®re table avec des donn√©es
        if not table and tables:
            table = tables[0]
        
        if not table:
            raise Exception("Aucun tableau trouv√© dans la page HTML")
        
        # Extraire les lignes
        rows = table.find_all('tr')
        if len(rows) < 2:
            raise Exception("Tableau vide ou insuffisamment de lignes")
        
        # Extraire les en-t√™tes
        headers = []
        if rows[0].find('th'):
            headers = [th.get_text(strip=True) for th in rows[0].find_all('th')]
        else:
            # Deviner les en-t√™tes bas√©s sur le contenu fourni
            headers = ['Symbole', 'Nom', 'Volume', 'Cours veille (FCFA)', 
                      'Cours Ouverture (FCFA)', 'Cours Cl√¥ture (FCFA)', 'Variation (%)']
        
        # Extraire les donn√©es
        data = []
        for row in rows[1:]:  # Skip la premi√®re ligne (en-t√™tes)
            cols = row.find_all('td')
            if len(cols) >= 7:  # On attend au moins 7 colonnes
                row_data = {
                    'Symbole': cols[0].get_text(strip=True),
                    'Nom': cols[1].get_text(strip=True),
                    'Volume': cols[2].get_text(strip=True).replace(' ', ''),
                    'Cours veille (FCFA)': cols[3].get_text(strip=True).replace(' ', ''),
                    'Cours Ouverture (FCFA)': cols[4].get_text(strip=True).replace(' ', ''),
                    'Cours Cl√¥ture (FCFA)': cols[5].get_text(strip=True).replace(' ', ''),
                    'Variation (%)': cols[6].get_text(strip=True).replace(',', '.')
                }
                data.append(row_data)
        
        if not data:
            raise Exception("Aucune donn√©e extraite du tableau")
        
        # Cr√©er le DataFrame
        df = pd.DataFrame(data)
        
        # Convertir les colonnes num√©riques
        numeric_cols = ['Volume', 'Cours veille (FCFA)', 'Cours Ouverture (FCFA)', 
                       'Cours Cl√¥ture (FCFA)', 'Variation (%)']
        
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Debug: afficher les premi√®res lignes
        st.sidebar.write(f"Donn√©es extraites: {len(df)} lignes")
        
        return df, "Donn√©es BRVM r√©elles"
        
    except requests.exceptions.Timeout:
        raise Exception("Timeout: Le site BRVM ne r√©pond pas (d√©lai d√©pass√©)")
    except requests.exceptions.ConnectionError:
        raise Exception("Erreur de connexion: Impossible d'atteindre le site BRVM")
    except requests.exceptions.HTTPError as e:
        raise Exception(f"Erreur HTTP {e.response.status_code}: Acc√®s refus√©")
    except Exception as e:
        raise Exception(f"Erreur de scraping: {str(e)}")

# Interface principale
st.sidebar.header("Configuration")

# Bouton pour rafra√Æchir
if st.sidebar.button("üîÑ Forcer le rafra√Æchissement"):
    st.cache_data.clear()
    st.rerun()

# Afficher le statut
st.sidebar.subheader("Statut")
status_placeholder = st.sidebar.empty()

try:
    # Tentative de scraping
    status_placeholder.info("‚è≥ Connexion au site BRVM...")
    
    with st.spinner("Scraping en cours... Cela peut prendre quelques secondes"):
        df, source = scrape_brvm_data()
    
    status_placeholder.success("‚úÖ Donn√©es charg√©es avec succ√®s")
    
    # Afficher les donn√©es
    st.success(f"‚úÖ Scraping r√©ussi - {len(df)} actions r√©cup√©r√©es")
    st.write(f"**Source:** {source}")
    
    # Afficher le DataFrame brut
    st.subheader("üìã Donn√©es brutes BRVM")
    st.dataframe(df, use_container_width=True, height=500)
    
    # Options de t√©l√©chargement
    st.subheader("üíæ T√©l√©chargement")
    
    # Format CSV
    csv = df.to_csv(index=False, encoding='utf-8-sig')
    st.download_button(
        label="üì• T√©l√©charger en CSV",
        data=csv,
        file_name=f"brvm_{datetime.now().strftime('%Y%m%d')}.csv",
        mime="text/csv",
        help="T√©l√©chargez les donn√©es au format CSV"
    )
    
    # Format Excel
    excel_buffer = pd.ExcelWriter('brvm_data.xlsx', engine='openpyxl')
    df.to_excel(excel_buffer, index=False)
    excel_buffer.close()
    
    with open('brvm_data.xlsx', 'rb') as f:
        excel_data = f.read()
    
    st.download_button(
        label="üìä T√©l√©charger en Excel",
        data=excel_data,
        file_name=f"brvm_{datetime.now().strftime('%Y%m%d')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        help="T√©l√©chargez les donn√©es au format Excel"
    )
    
    # Statistiques rapides
    st.subheader("üìà Statistiques")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if 'Variation (%)' in df.columns:
            avg_var = df['Variation (%)'].mean()
            st.metric("Variation moyenne", f"{avg_var:.2f}%")
    
    with col2:
        if 'Cours Cl√¥ture (FCFA)' in df.columns:
            max_price = df['Cours Cl√¥ture (FCFA)'].max()
            st.metric("Cours max", f"{max_price:,.0f} FCFA")
    
    with col3:
        if 'Volume' in df.columns:
            total_volume = df['Volume'].sum()
            st.metric("Volume total", f"{total_volume:,.0f}")
    
except Exception as e:
    # Affichage de l'erreur
    status_placeholder.error("‚ùå √âchec du scraping")
    
    st.error("""
    ## ‚ùå Impossible d'acc√©der aux donn√©es BRVM
    
    **Probl√®me d√©tect√©:** `{}`
    
    ### Causes possibles:
    1. üîí **Le site BRVM bloque l'acc√®s** aux robots/scrapers
    2. üåê **Probl√®me de connexion** internet
    3. üöß **Site BRVM en maintenance** ou inaccessible
    4. üîÑ **Structure du site modifi√©e**
    
    ### Solutions √† essayer:
    - ‚è±Ô∏è **Attendez quelques minutes** et r√©essayez
    - üîÑ **Cliquez sur 'Forcer le rafra√Æchissement'** dans la sidebar
    - üåç **V√©rifiez manuellement** le site: [BRVM Cours Actions](https://www.brvm.org/fr/cours-actions/0)
    - üõ°Ô∏è **Le site peut n√©cessiter** un proxy ou un navigateur avec JavaScript
    
    ### Code d'erreur technique:
    ```python
    {}
    ```
    """.format(str(e), str(e)))
    
    # Afficher des informations de d√©bogage
    with st.expander("üîß Informations de d√©bogage"):
        st.write("**Headers utilis√©s pour la requ√™te:**")
        st.code("""
        User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124
        Accept: text/html,application/xhtml+xml,application/xml
        Accept-Language: fr,fr-FR
        """)
        
        st.write("**Pour tester manuellement:**")
        st.markdown("""
        1. Ouvrez [https://www.brvm.org/fr/cours-actions/0](https://www.brvm.org/fr/cours-actions/0)
        2. V√©rifiez si la page s'affiche
        3. Inspectez la page (F12) pour voir le tableau
        """)

# Pied de page
st.sidebar.markdown("---")
st.sidebar.markdown("""
**‚ÑπÔ∏è √Ä propos:**
- **Type:** Scraping r√©el uniquement
- **Source:** Site BRVM officiel
- **Pas de donn√©es simul√©es**
- **Derni√®re tentative:** {}
""".format(datetime.now().strftime("%H:%M:%S")))
